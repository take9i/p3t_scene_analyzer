{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "def get_body(fpath):\n",
    "    return path.splitext(path.basename(fpath))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "from torch import nn\n",
    "\n",
    "def setup(model_name):\n",
    "    feature_extractor = SegformerFeatureExtractor.from_pretrained(model_name)\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(model_name)\n",
    "    return feature_extractor, model\n",
    "\n",
    "def predict(feature_extractor, model, image):\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "\n",
    "    upsampled_logits = nn.functional.interpolate(logits,\n",
    "                    size=(image.size[1], image.size[0]), # (height, width)\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False)\n",
    "        \n",
    "    predicted_mask = upsampled_logits.argmax(dim=1).cpu().numpy()\n",
    "    return predicted_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "def visualize(labels, image, prediction):\n",
    "    classes, palette = labels['classes'], labels['palette']\n",
    "    color_map = {i : k for i, k in enumerate(palette)}\n",
    "    vis = np.zeros(prediction.shape + (3,))\n",
    "    for i, c in color_map.items():\n",
    "        vis[prediction == i] = color_map[i]\n",
    "    mask = Image.fromarray(vis.astype(np.uint8))\n",
    "    overlayed_img = Image.blend(image.convert(\"RGB\"), mask.convert(\"RGB\"), 0.5)\n",
    "\n",
    "    hist, bins = np.histogram(prediction, range(0, len(classes)))\n",
    "    histbins = sorted([(h, b)for h, b in zip(hist, bins)], reverse=True)\n",
    "    n_o_pixels = mask.size[0] * mask.size[1]\n",
    "    stats = [(classes[b], (np.array(palette[b]) / 255).tolist(), r) for h, b in histbins if (r:=(int(h) * 100 / n_o_pixels)) > 0.1]\n",
    "    kinds, colors, ratios = list(zip(*stats))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10), layout=\"constrained\")\n",
    "    spec = fig.add_gridspec(2, 2)\n",
    "    ax00 = fig.add_subplot(spec[0, 0])\n",
    "    ax01 = fig.add_subplot(spec[0, 1])\n",
    "    ax0 = fig.add_subplot(spec[1, :])\n",
    "    ax00.imshow(mask)\n",
    "    ax01.imshow(overlayed_img)\n",
    "    ax0.bar(kinds, ratios, color=colors)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xxx_labels.json is mady from the codes on here\n",
    "# ade_labels.json: https://github.com/NVlabs/SegFormer/blob/master/mmseg/datasets/ade.py\n",
    "# cityscapes_labels.json: https://github.com/NVlabs/SegFormer/blob/master/mmseg/datasets/cityscapes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import partial\n",
    "import requests\n",
    "\n",
    "ade_predict = partial(predict, *setup(\"nvidia/segformer-b0-finetuned-ade-512-512\"))\n",
    "ade_labels = json.load(open('ade_labels.json'))\n",
    "ade_visualize = partial(visualize, ade_labels)\n",
    "\n",
    "def ade_analyze(url):\n",
    "    image = Image.open(requests.get(url, stream=True).raw)\n",
    "    prediction = ade_predict(image)\n",
    "    fig = ade_visualize(image, prediction)\n",
    "    hist, bins = np.histogram(prediction, range(len(ade_labels['classes'])))\n",
    "    hist = (hist * 100 / (image.size[0] * image.size[1])).astype(np.int32)\n",
    "    body = get_body(url)\n",
    "    fig.savefig(f'_segmented/{body}.png')\n",
    "    json.dump(hist.tolist(), open(f'_segmented/{body}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_analyze(\"http://images.cocodataset.org/val2017/000000039769.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "cc_predict = partial(predict, *setup(\"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\"))\n",
    "cc_labels = json.load(open('cityscapes_labels.json'))\n",
    "cc_visualize = partial(visualize, cc_labels)\n",
    "\n",
    "def cc_analyze(url):\n",
    "    image = Image.open(url).convert('RGB')\n",
    "    prediction = cc_predict(image)\n",
    "    fig = cc_visualize(image, prediction)\n",
    "    hist, bins = np.histogram(prediction, range(len(cc_labels['classes'])))\n",
    "    hist = (hist * 100 / (image.size[0] * image.size[1])).astype(np.int32)\n",
    "    body = get_body(url)\n",
    "    fig.savefig(f'_segmented/{body}.png')\n",
    "    json.dump(hist.tolist(), open(f'_segmented/{body}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_analyze(\"../scene_capture/_captured/tky-2_0_-80.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# for fname in glob(\"../scene_capture/_captured/tky-*.png\"):\n",
    "# for fname in glob(\"../scene_capture/_captured/osk-*.png\"):\n",
    "# for fname in glob(\"../scene_capture/_captured/ngy-*.png\"):\n",
    "# for fname in glob(\"../scene_capture/_captured/sap-*.png\"):\n",
    "for fname in glob(\"../scene_capture/_captured/fuk-*.png\"):\n",
    "    cc_analyze(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
